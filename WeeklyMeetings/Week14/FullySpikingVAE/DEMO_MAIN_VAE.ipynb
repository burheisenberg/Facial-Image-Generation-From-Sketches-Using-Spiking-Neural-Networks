{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b24a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import logging\n",
    "import argparse\n",
    "import pycuda.driver as cuda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import global_v as glv\n",
    "from network_parser import parse\n",
    "from datasets import load_dataset_snn, load_dataset_snn2, load_dataset_snn3\n",
    "from utils import aboutCudaDevices\n",
    "from utils import AverageMeter\n",
    "from utils import CountMulAddSNN, CountMulAddANN\n",
    "import fsvae_models.fsvae as fsvae\n",
    "import ann_models.ann_vae as ann_vae\n",
    "from fsvae_models.snn_layers import LIFSpike\n",
    "import metrics.inception_score as inception_score\n",
    "import metrics.clean_fid as clean_fid\n",
    "import metrics.autoencoder_fid as autoencoder_fid\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from ann_models import *\n",
    "\n",
    "\n",
    "max_accuracy = 0\n",
    "min_loss = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076e40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "def plot(network, testloader, index):\n",
    "    n_steps = glv.network_config['n_steps']\n",
    "    max_epoch = glv.network_config['epochs']\n",
    "\n",
    "    network = network.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (real_img, targets) in enumerate(testloader):   \n",
    "            if batch_idx == index:\n",
    "                \n",
    "                real_img = real_img.to(init_device, non_blocking=True)\n",
    "                targets = targets.to(init_device, non_blocking=True)\n",
    "                if glv.network_config['spiking']:\n",
    "                    # direct spike input\n",
    "                    spike_input = real_img.unsqueeze(-1).repeat(1, 1, 1, 1, n_steps) # (N,C,H,W,T)\n",
    "                    x_recon, q_z, p_z, sampled_z = network(spike_input, scheduled=network_config['scheduled']) # sampled_z(B,C,1,1,T)\n",
    "                else:\n",
    "                    # direct input\n",
    "                    x_recon, mu, logvar = network(real_img)\n",
    "\n",
    "                real_img = np.transpose(real_img.cpu().numpy(), (0,2,3,1))\n",
    "                # reshape x_recon to use matplotlib\n",
    "                x_recon = np.transpose(x_recon.cpu().numpy(), (0, 2, 3, 1))\n",
    "                \n",
    "                real_img = (real_img+1)/2\n",
    "                x_recon = (x_recon+1)/2\n",
    "                \n",
    "                N = 2*x_recon.shape[0]\n",
    "                if N>4:\n",
    "                    cols = 4\n",
    "                    rows = int(np.ceil(N/4))\n",
    "                else:\n",
    "                    cols = N\n",
    "                    rows = 1\n",
    "                fig, axes = plt.subplots(rows, cols, figsize=(10,20))\n",
    "                for i, ax in enumerate(axes.flat):\n",
    "                    if i < N:\n",
    "                        if i % 2 == 0:\n",
    "                            ax.imshow(real_img[int(i//2)])\n",
    "                            ax.axis('off')\n",
    "                        else:\n",
    "                            ax.imshow(x_recon[int(i//2)])\n",
    "                            ax.axis('off')\n",
    "                    else:\n",
    "                        ax.axis('off')\n",
    "                        \n",
    "                plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "                #plt.show()\n",
    "        # Save the figure in high resolution\n",
    "        plt.savefig('output_plot.png', dpi=600, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8007f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3586df4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 50, 'batch_size': 40, 'n_steps': 8, 'dataset': 'ToyCelebA', 'in_channels': 3, 'out_channels': 3, 'input_data_path': 'C:/Users/Brhan/OneDrive/Belgeler/KuOnline/Spring24/Elec491/SNN/dataset/img_align_celeba_sketch', 'output_data_path': 'C:/Users/Brhan/OneDrive/Belgeler/KuOnline/Spring24/Elec491/SNN/dataset/img_align_celeba', 'lr': 0.001, 'latent_dim': 128, 'input_size': 32, 'model': 'VanillaVAE_large', 'k': 20, 'scheduled': False, 'loss_func': 'kld', 'spiking': False}\n",
      "1 device(s) found:\n",
      "    1) NVIDIA GeForce GTX 1650 (Id: 0)\n",
      "          Memory: 4.29 GB\n",
      "\n",
      "selected device:  None\n",
      "loading ToyCelebA\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, checkpoint=None, config=\"\", device=None, name=\"\"):\n",
    "        self.checkpoint = checkpoint\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.name = name\n",
    "\n",
    "checkpoint_ann='checkpoint/ann_model_test/best.pth'\n",
    "args = Args(checkpoint=checkpoint_ann, config='NetworkConfigs/ToyCelebA_ANN.yaml', device=None, name='ann_model_test')\n",
    "\n",
    "if args.device is None:\n",
    "    init_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    init_device = torch.device(f\"cuda:{args.device}\")\n",
    "    \n",
    "os.makedirs(f'checkpoint/{args.name}', exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=f'checkpoint/{args.name}/tb')\n",
    "logging.basicConfig(filename=f'checkpoint/{args.name}/{args.name}.log', level=logging.INFO)\n",
    "    \n",
    "logging.info(\"start parsing settings\")\n",
    "    \n",
    "params = parse(args.config)\n",
    "network_config = params['Network']\n",
    "\n",
    "if network_config.get('out_channels') is None:\n",
    "    network_config['out_channels'] = network_config['in_channels']\n",
    "    \n",
    "logging.info(\"finish parsing settings\")\n",
    "logging.info(network_config)\n",
    "print(network_config)\n",
    "        \n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    cuda.init()\n",
    "    c_device = aboutCudaDevices()\n",
    "    print(c_device.info())\n",
    "    print(\"selected device: \", args.device)\n",
    "else:\n",
    "    raise Exception(\"only support gpu\")\n",
    "    \n",
    "glv.init(network_config, [args.device])\n",
    "\n",
    "dataset_name = glv.network_config['dataset']\n",
    "\n",
    "logging.info(\"dataset loading...\")\n",
    "\n",
    "if dataset_name == \"ToyCelebA\":\n",
    "    input_data_path = glv.network_config['input_data_path']\n",
    "    output_data_path = glv.network_config['output_data_path']\n",
    "    input_data_path = os.path.expanduser(input_data_path)\n",
    "    output_data_path = os.path.expanduser(output_data_path)\n",
    "    train_loader, test_loader = load_dataset_snn2.load_toyceleba(input_data_path, output_data_path)\n",
    "else:\n",
    "    data_path = glv.network_config['data_path']\n",
    "\n",
    "    if dataset_name == \"MNIST\":\n",
    "        data_path = os.path.expanduser(data_path)\n",
    "        train_loader, test_loader = load_dataset_snn.load_mnist(data_path)\n",
    "    elif dataset_name == \"FashionMNIST\":\n",
    "        data_path = os.path.expanduser(data_path)\n",
    "        train_loader, test_loader = load_dataset_snn.load_fashionmnist(data_path)\n",
    "\n",
    "    elif dataset_name == \"CIFAR10\":\n",
    "        data_path = os.path.expanduser(data_path)\n",
    "        train_loader, test_loader = load_dataset_snn.load_cifar10(data_path)\n",
    "\n",
    "    elif dataset_name == \"CelebA\":\n",
    "        data_path = os.path.expanduser(data_path)\n",
    "        train_loader, test_loader = load_dataset_snn.load_celebA(data_path)\n",
    "\n",
    "    else:\n",
    "        raise Exception('Unrecognized dataset name.')\n",
    "logging.info(\"dataset loaded\")\n",
    "\n",
    "if network_config['model'] == 'FSVAE':\n",
    "    net = fsvae.FSVAE()\n",
    "elif network_config['model'] == 'FSVAE_large':\n",
    "    net = fsvae.FSVAELarge()\n",
    "elif network_config['model'] == 'FSVAE_small':\n",
    "    net = fsvae.FSVAESmall()\n",
    "elif network_config['model'] == 'FSAE_small':\n",
    "    net = fsvae.FSAESmall()\n",
    "elif network_config['model'] == 'VanillaVAE_large':\n",
    "    net = ann_vae.VanillaVAELarge()\n",
    "elif network_config['model'] == 'AE':\n",
    "    net = ann_ae.AE()\n",
    "elif network_config['model'] == 'AE_large':\n",
    "    net = ann_ae.AELarge()\n",
    "else:\n",
    "    raise Exception('not defined model')\n",
    "\n",
    "net = net.to(init_device)\n",
    "    \n",
    "if args.checkpoint is not None:\n",
    "    checkpoint_path = args.checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    net.load_state_dict(checkpoint)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44faa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "#sample(net, e, batch_size=2)\n",
    "#calc_inception_score(net, e)\n",
    "#calc_autoencoder_frechet_distance(net, e)\n",
    "#calc_clean_fid(net, e)\n",
    "\n",
    "# Plot the first batch from the test_loader\n",
    "plot(net, test_loader, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be836edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c46a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
